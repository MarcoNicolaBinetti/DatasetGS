---
title: "analisi preliminare"
author: "MNB"
date: "4/25/2024"
output: html_document
---

# load libraries
```{r}
library(plyr)
library(dplyr)
library(tidyverse)
library(tidyr)
library(naniar)
library(ggplot2)
library(nnet)
library(stargazer)
library(brms)
library(nnet)
library(sandwich)
library(lmtest)

```


# Remove lists 
```{r, include=FALSE}
## remove lists
rm(list=ls())
```

# Functions
```{r}
# exclude
'%!in%' <- function(x,y)!('%in%'(x,y))

# Function to scale a variable to the 0-1 range
scale_0_1 <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}


# Define the function to generate a variable chain suitable for a model
gen_formula <- function(dependent_var, var_list) {
  # Concatenate the variable names with " + " as separator
  var_chain <- paste(var_list, collapse = " + ")

  complete_formula <- as.formula(paste(dependent_var, var_chain, sep = " ~ "))

    
  # Return the concatenated variable chain
  return(complete_formula)
}


```


# Import DFs
## Set folders
```{r}
## set url
desktop_path <- file.path("C:", "Users", "marco", "Desktop")
main_folder_name <- "DFGlobalLab"
sub_folder_name <- "Compiled"
```

## Import Globsol dataset
```{r}
# set DF
DF<-c("globsol_20240313.rds")
# load DF
Df_path <- file.path(desktop_path, main_folder_name, sub_folder_name, DF )
# importing DF 
df_Globsol <- readRDS(Df_path)

```

## Import Independent and control variables
```{r}
# set DF
DF<-c("df_ind_var.rds")
# load DF
Df_path <- file.path(desktop_path, main_folder_name, sub_folder_name, DF )
# importing DF 
df_IndVars <- readRDS(Df_path)

```

# Merge dfs
```{r}
df_full <- left_join(df_Globsol, df_IndVars, by = c("year" = "year", "iso3c" = "iso3c"))

## remove useless vars
# keep var of interest
df_full <- df_full[ , names(df_full) %!in% c("country.x",
                                            "country.y",
                                            "country_wb",
                                            "disaster")] 
```

# start analysis
## preprocess data
```{r}

## select vars if interest
df_model_data <- df_full[ , names(df_full) %in% c("GlobSol",
                                                   "count_HO_lag_1",
                                                   "nat_rents_lag_1",
                                                   "trade_part_lag_1",
                                                   "pop_tot_lag_1",
                                                   "gdp_lag_1",
                                                   "inflation_lag_1",
                                                   "food_import_lag_1",
                                                   "urb_pop_pct_lag_1",
                                                  "oil_rents_lag_1",
                                                  "gas_rents_lag_1",
                                                  "minerals_rents_lag_1",
                                                  "trade_lag_1",
                                                  "liberal_demo_lag_1",
                                                  "regime_corruption_lag_1",
                                                  "military_centr_lag_1",
                                                  
                        "iso3c",
                        "year")] 

## drop NAs
df_model_data <- na.omit(df_model_data)

# List of variable names to scale
variables_to_scale <- c("count_HO_lag_1",
                         "nat_rents_lag_1",
                         "trade_part_lag_1",
                         "pop_tot_lag_1",
                         "gdp_lag_1",
                         "inflation_lag_1",
                         "food_import_lag_1",
                         "urb_pop_pct_lag_1",
                        "oil_rents_lag_1",
                        "gas_rents_lag_1",
                        "minerals_rents_lag_1",
                        "trade_lag_1",
                        "liberal_demo_lag_1",
                        "regime_corruption_lag_1",
                        "military_centr_lag_1")

# Apply  scaling function to the specified variables
df_scaled<-df_model_data
df_scaled[variables_to_scale] <- lapply(df_scaled[variables_to_scale], scale_0_1)

## set fixed effects
df_scaled$iso3c <- as.factor(df_scaled$iso3c)
df_scaled$year <- as.factor(df_scaled$year)

# Check the distribution of the Globsol variable
table(df_scaled$GlobSol)

#add index column to data frame
df_scaled$index <- 1:nrow(df_scaled)
```

## Export file
```{r}
#saving it
namefile<-"df_full.csv"
folder_path_wb <- file.path(desktop_path, main_folder_name, sub_folder_name, namefile)
write.csv(df_scaled, folder_path_wb, row.names = FALSE)  # row.names = FALSE to exclude row indices

```


## Run multinomial model
```{r}
# Define the dependent variable and set is as an unordered factors
dependent_var <- "GlobSol"
df_scaled$GlobSol <- factor(df_scaled$GlobSol)  # Ensure it's a factor
# Re-level the target variable to set 4 as the baseline
df_scaled$GlobSol <- relevel(df_scaled$GlobSol, ref = "4")


main_indip <- c("count_HO_lag_1", "trade_part_lag_1", "nat_rents_lag_1")
econo <- c("pop_tot_lag_1", "gdp_lag_1","inflation_lag_1","urb_pop_pct_lag_1")
socio_poli <- c("liberal_demo_lag_1", "military_centr_lag_1","regime_corruption_lag_1")


# baseline model
Vars<-main_indip
# Create the complete formula
complete_formula <-gen_formula(dependent_var,Vars)
# Estimate the multinomial logistic regression model
multinom_model1 <- multinom(complete_formula, data = df_scaled)

# Economic controls
Vars<-c(main_indip,econo)
# Create the complete formula
complete_formula <-gen_formula(dependent_var,Vars) 
# Estimate the multinomial logistic regression model
multinom_model2 <- multinom(complete_formula, data = df_scaled)


# Political controls
Vars<-c(main_indip,socio_poli)
# Create the complete formula
complete_formula <-gen_formula(dependent_var,Vars) 
# Estimate the multinomial logistic regression model
multinom_model3 <- multinom(complete_formula, data = df_scaled)


# Full controls
Vars<-c(main_indip,econo,socio_poli)
# Create the complete formula
complete_formula <-gen_formula(dependent_var,Vars) 
# Estimate the multinomial logistic regression model
multinom_model4 <- multinom(complete_formula, data = df_scaled)


```

```{r}
# Create a comparison table with stargazer
stargazer(
  multinom_model1, multinom_model2, multinom_model3, multinom_model4,
  type = "text",  # or "latex" or "html" for different output formats
  title = "Comparison of Multinomial Models",
  align = TRUE,
  no.space = TRUE,
  digits = 3,  # Number of decimal places to display
  column.labels = c("Model 1", "Model 2", "Model 3"),  # Label each model
  omit.stat = c("aic", "bic")  # Optionally omit some statistics for cleaner output
)
```


### plotting effects on predictions
# plot marginal effects count ho
```{r}

df<-df_scaled
# Create a new data frame for prediction
# You can use sequences, random data, or actual data points for input
newdata <- data.frame(
  count_HO_lag_1 = seq(min(df$count_HO_lag_1), max(df$count_HO_lag_1), length.out = length(df$count_HO_lag_1)),
  trade_part_lag_1 = mean(df$trade_part_lag_1),
  nat_rents_lag_1 = mean(df$nat_rents_lag_1),
  pop_tot_lag_1 = mean(df$pop_tot_lag_1),
  gdp_lag_1 = mean(df$gdp_lag_1),
  inflation_lag_1 = mean(df$inflation_lag_1),
  urb_pop_pct_lag_1 = mean(df$urb_pop_pct_lag_1),
  liberal_demo_lag_1 = mean(df$liberal_demo_lag_1),
    military_centr_lag_1 = mean(df$military_centr_lag_1),
    regime_corruption_lag_1 = mean(df$regime_corruption_lag_1)
)

# Generate predicted probabilities for each category
predictions <- predict(multinom_model4, newdata, "probs")


# Create a data frame with predictions
plot_data <- cbind(newdata, predictions)

# Load ggplot2 for visualization
library(ggplot2)

# Plot the predicted probabilities
ggplot(plot_data, aes(x = count_HO_lag_1)) +
  geom_line(aes(y = `1`, color = "Category 1")) +
  geom_line(aes(y = `2`, color = "Category 2")) +
  geom_line(aes(y = `3`, color = "Category 3")) +
  geom_line(aes(y = `4`, color = "Category 4")) +
  labs(y = "Predicted Probability", x = "count_HO_lag_1", color = "Category") +
  theme_minimal() +
  ggtitle("Predicted Probabilities by count_HO_lag_1")
```

# plot marginal effects count trade
```{r}

df<-df_scaled
# Create a new data frame for prediction
# You can use sequences, random data, or actual data points for input
newdata <- data.frame(
  trade_part_lag_1 = seq(min(df$trade_part_lag_1), max(df$trade_part_lag_1), length.out = length(df$count_HO_lag_1)),
  count_HO_lag_1 = mean(df$count_HO_lag_1),
  nat_rents_lag_1 = mean(df$nat_rents_lag_1),
  pop_tot_lag_1 = mean(df$pop_tot_lag_1),
  gdp_lag_1 = mean(df$gdp_lag_1),
  inflation_lag_1 = mean(df$inflation_lag_1),
  urb_pop_pct_lag_1 = mean(df$urb_pop_pct_lag_1),
  liberal_demo_lag_1 = mean(df$liberal_demo_lag_1),
    military_centr_lag_1 = mean(df$military_centr_lag_1),
    regime_corruption_lag_1 = mean(df$regime_corruption_lag_1)
)

# Generate predicted probabilities for each category
predictions <- predict(multinom_model4, newdata, "probs")


# Create a data frame with predictions
plot_data <- cbind(newdata, predictions)

# Load ggplot2 for visualization
library(ggplot2)

# Plot the predicted probabilities
ggplot(plot_data, aes(x = trade_part_lag_1)) +
  geom_line(aes(y = `1`, color = "Category 1")) +
  geom_line(aes(y = `2`, color = "Category 2")) +
  geom_line(aes(y = `3`, color = "Category 3")) +
  geom_line(aes(y = `4`, color = "Category 4")) +
  labs(y = "Predicted Probability", x = "trade_part_lag_1", color = "Category") +
  theme_minimal() +
  ggtitle("Predicted Probabilities by trade_part_lag_1")
```


# plot marginal effects nat revs
```{r}

df<-df_scaled
# Create a new data frame for prediction
# You can use sequences, random data, or actual data points for input
newdata <- data.frame(
  nat_rents_lag_1 = seq(min(df$nat_rents_lag_1), max(df$nat_rents_lag_1), length.out = length(df$count_HO_lag_1)),
  count_HO_lag_1 = mean(df$count_HO_lag_1),
  trade_part_lag_1 = mean(df$trade_part_lag_1),
  pop_tot_lag_1 = mean(df$pop_tot_lag_1),
  gdp_lag_1 = mean(df$gdp_lag_1),
  inflation_lag_1 = mean(df$inflation_lag_1),
  urb_pop_pct_lag_1 = mean(df$urb_pop_pct_lag_1),
  liberal_demo_lag_1 = mean(df$liberal_demo_lag_1),
    military_centr_lag_1 = mean(df$military_centr_lag_1),
    regime_corruption_lag_1 = mean(df$regime_corruption_lag_1)
)

# Generate predicted probabilities for each category
predictions <- predict(multinom_model4, newdata, "probs")


# Create a data frame with predictions
plot_data <- cbind(newdata, predictions)

# Load ggplot2 for visualization
library(ggplot2)

# Plot the predicted probabilities
ggplot(plot_data, aes(x = nat_rents_lag_1)) +
  geom_line(aes(y = `1`, color = "Category 1")) +
  geom_line(aes(y = `2`, color = "Category 2")) +
  geom_line(aes(y = `3`, color = "Category 3")) +
  geom_line(aes(y = `4`, color = "Category 4")) +
  labs(y = "Predicted Probability", x = "nat_rents_lag_1", color = "Category") +
  theme_minimal() +
  ggtitle("Predicted Probabilities by nat_rents_lag_1")
```












## getting robust se
```{r}


```



```{r}
# Use stargazer to create a summary with custom standard errors
stargazer(
  multinom_model1,
  type = "text",
  se = list(bootstrap_se),
  title = "Multinomial Model with Robust Standard Errors",
  dep.var.labels = "GlobSol",
  covariate.labels = c("Count Ho Lag 1", "Trade Part Lag 1", "Nat Rents Lag 1"),
  out.header = TRUE
)
```


## Test nested models

```{r}
df_long <- mlogit.data(df_scaled, 
                       choice = "GlobSol", 
                       shape = "wide", 
                       id.var = "index", 
                       varying = NULL, 
                       sep = "")

nesting_structure <- list(
  Nest1 = c("1", "2"), 
  Nest2 = c("3", "4")
)

head(df_long)

model <- mlogit(GlobSol ~ count_HO_lag_1 + nat_rents_lag_1 + trade_lag_1, 
                data = df_long, 
                nests = nesting_structure)

# Display summary
summary(model)


cor_matrix <- cor(df_scaled[, c("variable1", "variable2", "variable3")], use = "complete.obs")

print(cor_matrix)
```








